# Guide d'installation d'Ollama pour Photography Club FSM

Ce guide vous aidera √† installer et configurer Ollama pour utiliser l'assistant IA ÿ±ÿ§Ÿäÿß (Roya).

## üì• Installation d'Ollama

### Option 1: Installation automatique (Recommand√©e)

1. **T√©l√©chargez Ollama:**
   - Allez sur https://ollama.ai/download
   - Cliquez sur "Download for Windows"
   - Ex√©cutez le fichier d'installation t√©l√©charg√©

2. **Installez:**
   - Suivez les instructions de l'installateur
   - Ollama sera install√© et d√©marr√© automatiquement

### Option 2: Installation via PowerShell (Windows)

```powershell
# T√©l√©charger et installer Ollama
winget install Ollama.Ollama
```

## üöÄ D√©marrage d'Ollama

### V√©rifier que Ollama est install√©

Ouvrez PowerShell ou CMD et tapez:
```bash
ollama --version
```

### D√©marrer le serveur Ollama

```bash
ollama serve
```

**Important:** Gardez cette fen√™tre ouverte! Le serveur doit rester actif.

## üì¶ T√©l√©charger un mod√®le

Une fois Ollama d√©marr√©, ouvrez **une nouvelle fen√™tre** de terminal et t√©l√©chargez un mod√®le:

### Mod√®le recommand√©: Llama 3.2 (3B - L√©ger et rapide)

```bash
ollama pull llama3.2
```

### Autres mod√®les disponibles:

**Pour d√©buter (petits et rapides):**
```bash
ollama pull phi3          # 3.8B - Tr√®s rapide
ollama pull mistral       # 7B - Bon √©quilibre
```

**Pour de meilleures performances (plus gros):**
```bash
ollama pull llama3.1:8b   # 8B - Plus performant
ollama pull mistral:7b    # 7B - Excellent pour le fran√ßais
```

## ‚úÖ V√©rifier l'installation

Testez que tout fonctionne:

```bash
# V√©rifier que le serveur r√©pond
curl http://localhost:11434/api/tags

# Tester une requ√™te simple
ollama run llama3.2 "Bonjour, comment √ßa va?"
```

## üîß Configuration pour Photography Club FSM

### Variables d'environnement (optionnel)

Cr√©ez ou modifiez `.env.local` dans votre projet:

```env
OLLAMA_API_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=llama3.2
```

### D√©marrer Ollama automatiquement au d√©marrage (Optionnel)

1. Appuyez sur `Win + R`
2. Tapez `shell:startup` et appuyez sur Entr√©e
3. Cr√©ez un fichier `start-ollama.bat` avec ce contenu:

```batch
@echo off
cd /d C:\Users\%USERNAME%\AppData\Local\Programs\Ollama
ollama serve
```

## üéØ Utilisation avec ÿ±ÿ§Ÿäÿß (Roya)

Une fois Ollama install√© et d√©marr√©:

1. **D√©marrez Ollama:**
   ```bash
   ollama serve
   ```

2. **Dans un autre terminal, t√©l√©chargez le mod√®le:**
   ```bash
   ollama pull llama3.2
   ```

3. **D√©marrez votre application Next.js:**
   ```bash
   npm run dev
   ```

4. **Ouvrez votre site web** et cliquez sur le bouton de chat ÿ±ÿ§Ÿäÿß (Roya)

## üêõ D√©pannage

### Probl√®me: "ollama: command not found"
- V√©rifiez que Ollama est install√©
- Red√©marrez votre terminal
- Ajoutez Ollama au PATH si n√©cessaire

### Probl√®me: "Connection refused" ou "Cannot connect"
- V√©rifiez que `ollama serve` est en cours d'ex√©cution
- V√©rifiez que le port 11434 n'est pas bloqu√© par un firewall
- Essayez de red√©marrer Ollama

### Probl√®me: Le mod√®le ne se t√©l√©charge pas
- V√©rifiez votre connexion internet
- Le t√©l√©chargement peut prendre du temps (plusieurs GB)
- Assurez-vous d'avoir assez d'espace disque

### Probl√®me: R√©ponses lentes
- Utilisez un mod√®le plus petit (llama3.2 au lieu de llama3.1:8b)
- V√©rifiez que votre ordinateur a assez de RAM (minimum 8GB recommand√©)
- Fermez d'autres applications lourdes

## üìä Mod√®les recommand√©s par configuration

| Configuration | Mod√®le recommand√© | Taille | RAM n√©cessaire |
|--------------|-------------------|--------|----------------|
| Ordinateur basique | `llama3.2` | ~2GB | 4GB+ |
| Ordinateur moyen | `mistral` | ~4GB | 8GB+ |
| Ordinateur puissant | `llama3.1:8b` | ~5GB | 16GB+ |

## üí° Astuces

- **Premi√®re utilisation:** Le mod√®le sera t√©l√©charg√© automatiquement lors de la premi√®re utilisation
- **Performance:** Les mod√®les plus petits sont plus rapides mais moins performants
- **Fran√ßais:** Les mod√®les Mistral sont souvent meilleurs pour le fran√ßais
- **Mise √† jour:** Mettez √† jour Ollama r√©guli√®rement: `winget upgrade Ollama.Ollama`

## üîó Ressources

- Site officiel: https://ollama.ai
- Documentation: https://github.com/ollama/ollama
- Mod√®les disponibles: https://ollama.ai/library

---

**Note:** Si vous n'installez pas Ollama, ÿ±ÿ§Ÿäÿß (Roya) fonctionnera toujours avec le syst√®me FAQ int√©gr√©, mais les r√©ponses seront limit√©es aux questions pr√©d√©finies.

